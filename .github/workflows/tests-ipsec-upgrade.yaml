name: Cilium IPsec upgrade (ci-ipsec-upgrade)

# Any change in triggers needs to be reflected in the concurrency group.
on:
  workflow_dispatch:
    inputs:
      PR-number:
        description: "Pull request number."
        required: true
      context-ref:
        description: "Context in which the workflow runs. If PR is from a fork, will be the PR target branch (general case). If PR is NOT from a fork, will be the PR branch itself (this allows committers to test changes to workflows directly from PRs)."
        required: true
      SHA:
        description: "SHA under test (head of the PR branch)."
        required: true
      extra-args:
        description: "[JSON object] Arbitrary arguments passed from the trigger comment via regex capture group. Parse with 'fromJson(inputs.extra-args).argName' in workflow."
        required: false
        default: '{}'
  push:
    branches:
      - 'renovate/v1.15-**'

# By specifying the access of one of the scopes, all of those that are not
# specified are set to 'none'.
permissions:
  # To be able to access the repository with actions/checkout
  contents: read
  # To allow retrieving information from the PR API
  pull-requests: read
  # To be able to set commit status
  statuses: write

concurrency:
  # Structure:
  # - Workflow name
  # - Event type
  # - A unique identifier depending on event type:
  #   - schedule: SHA
  #   - workflow_dispatch: PR number
  #
  # This structure ensures a unique concurrency group name is generated for each
  # type of testing, such that re-runs will cancel the previous run.
  group: |
    ${{ github.workflow }}
    ${{ github.event_name }}
    ${{
      (github.event_name == 'push' && github.sha) ||
      (github.event_name == 'schedule' && github.sha) ||
      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)
    }}
  cancel-in-progress: true

env:
  cilium_cli_ci_version:

jobs:
  echo-inputs:
    if: ${{ github.event_name == 'workflow_dispatch' }}
    name: Echo Workflow Dispatch Inputs
    runs-on: ubuntu-24.04
    steps:
      - name: Echo Workflow Dispatch Inputs
        run: |
          echo '${{ tojson(inputs) }}'

  commit-status-start:
    name: Commit Status Start
    runs-on: ubuntu-latest
    steps:
      - name: Set initial commit status
        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1
        with:
          sha: ${{ inputs.SHA || github.sha }}

  wait-for-images:
    name: Wait for images
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - name: Checkout context ref (trusted)
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          ref: ${{ inputs.context-ref || github.sha }}
          persist-credentials: false
      - name: Wait for images
        uses: ./.github/actions/wait-for-images
        with:
          SHA: ${{ inputs.SHA }}

  setup-and-test:
    needs: [wait-for-images]
    runs-on: ${{ vars.GH_RUNNER_EXTRA_POWER_UBUNTU_LATEST || 'ubuntu-latest' }}
    name: 'Setup & Test'
    env:
      job_name: 'Setup & Test'
    strategy:
      fail-fast: false
      max-parallel: 16
      matrix:
        config: ['5.4', '5.10', '6.1', '6.6']
        mode: ['minor', 'patch']
        include:
          # Define three config sets
          - config: '5.4'
            # renovate: datasource=docker depName=quay.io/lvh-images/kind
            kernel: '5.4-20250521.025913'
            kube-proxy: 'iptables'
            kpr: 'disabled'
            tunnel: 'disabled'
            encryption: 'ipsec'

          - config: '5.10'
            # renovate: datasource=docker depName=quay.io/lvh-images/kind
            kernel: '5.10-20250521.025913'
            kube-proxy: 'iptables'
            kpr: 'disabled'
            tunnel: 'disabled'
            encryption: 'ipsec'
            endpoint-routes: 'true'
            kvstore: 'true'

          - config: '6.1'
            # renovate: datasource=docker depName=quay.io/lvh-images/kind
            kernel: '6.1-20250521.025913'
            kube-proxy: 'iptables'
            kpr: 'disabled'
            tunnel: 'vxlan'
            encryption: 'ipsec'
            endpoint-routes: 'false'
            kvstore: 'true'

          - config: '6.6'
            # renovate: datasource=docker depName=quay.io/lvh-images/kind
            kernel: '6.6-20250521.025913'
            kube-proxy: 'iptables'
            kpr: 'disabled'
            tunnel: 'vxlan'
            encryption: 'ipsec'
            endpoint-routes: 'true'

          # Add names to matrix combinations of {config, mode}
          - config: '5.4'
            mode: 'minor'
            name: '1'

          - config: '5.10'
            mode: 'minor'
            name: '2'

          - config: '6.1'
            mode: 'minor'
            name: '3'

          - config: '6.6'
            mode: 'minor'
            name: '4'

          - config: '5.4'
            mode: 'patch'
            name: '5'

          - config: '5.10'
            mode: 'patch'
            name: '6'

          - config: '6.1'
            mode: 'patch'
            name: '7'

          - config: '6.6'
            mode: 'patch'
            name: '8'

    timeout-minutes: 70
    steps:
      - name: Checkout context ref (trusted)
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          ref: ${{ inputs.context-ref || github.sha }}
          # We keep the credentials here, to make sure we're able to run
          # "git fetch" in print-downgrade-version.sh in a few steps below.
          # We'll call it again to remove the credentials before pulling the
          # untrusted branch from the PR. We remain in a trusted context while
          # credentials persist.
          # This remains faster than downloading the full project history to
          # make tags available to print-downgrade-version.sh.
          persist-credentials: true

      - name: Cleanup Disk space in runner
        if: runner.name == 'ubuntu-latest'
        uses: ./.github/actions/disk-cleanup

      - name: Set Environment Variables
        uses: ./.github/actions/set-env-variables

      - name: Set up job variables
        id: vars
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            SHA="${{ inputs.SHA }}"
          else
            SHA="${{ github.sha }}"
          fi
          echo sha=${SHA} >> $GITHUB_OUTPUT
          if [ "${{ matrix.mode }}" = "minor" ]; then
            CILIUM_DOWNGRADE_VERSION=$(contrib/scripts/print-downgrade-version.sh stable)
            IMAGE_TAG=${CILIUM_DOWNGRADE_VERSION}
          else
            # Upgrade from / downgrade to patch release.
            # In some cases we expect to fail to get the version number, do not
            # fail the workflow in such case. This is typically the case on
            # main branch where we don't have preceeding patch releases.
            CILIUM_DOWNGRADE_VERSION=$(contrib/scripts/print-downgrade-version.sh patch || true)
            # Pass an empty tag to the cilium-config action to fall back to the
            # default release image, without crafting an image path with the
            # "-ci" suffix
            IMAGE_TAG=''
          fi
          echo "CILIUM_DOWNGRADE_VERSION: ${CILIUM_DOWNGRADE_VERSION}"
          echo "IMAGE_TAG: ${IMAGE_TAG}"
          if [ -z "${CILIUM_DOWNGRADE_VERSION}" ]; then
            echo "::notice::No CILIUM_DOWNGRADE_VERSION returned; skipping remaining steps"
          fi
          echo downgrade_version=${CILIUM_DOWNGRADE_VERSION} >> $GITHUB_OUTPUT
          echo image_tag=${IMAGE_TAG} >> $GITHUB_OUTPUT

      - name: Call actions/checkout again to remove credentials
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          ref: ${{ inputs.context-ref || github.sha }}
          persist-credentials: false

      - name: Derive stable Cilium installation config
        id: cilium-stable-config
        if: ${{ steps.vars.outputs.downgrade_version != '' }}
        uses: ./.github/actions/cilium-config
        with:
          image-tag: ${{ steps.vars.outputs.image_tag }}
          chart-dir: './untrusted/cilium-downgrade/install/kubernetes/cilium'
          tunnel: ${{ matrix.tunnel }}
          endpoint-routes: ${{ matrix.endpoint-routes }}
          ipv6: ${{ matrix.ipv6 }}
          kpr: ${{ matrix.kpr }}
          lb-mode: ${{ matrix.lb-mode }}
          lb-acceleration: ${{ matrix.lb-acceleration }}
          encryption: ${{ matrix.encryption }}
          encryption-node: ${{ matrix.encryption-node }}
          egress-gateway: ${{ matrix.egress-gateway }}
          host-fw: ${{ matrix.host-fw }}
          mutual-auth: false
          misc: 'bpfClockProbe=false,cni.uninstall=false'

      - name: Derive newest Cilium installation config
        id: cilium-newest-config
        if: ${{ steps.vars.outputs.downgrade_version != '' }}
        uses: ./.github/actions/cilium-config
        with:
          image-tag: ${{ steps.vars.outputs.sha }}
          chart-dir: './untrusted/cilium-newest/install/kubernetes/cilium'
          tunnel: ${{ matrix.tunnel }}
          endpoint-routes: ${{ matrix.endpoint-routes }}
          ipv6: ${{ matrix.ipv6 }}
          kpr: ${{ matrix.kpr }}
          lb-mode: ${{ matrix.lb-mode }}
          lb-acceleration: ${{ matrix.lb-acceleration }}
          encryption: ${{ matrix.encryption }}
          encryption-node: ${{ matrix.encryption-node }}
          egress-gateway: ${{ matrix.egress-gateway }}
          host-fw: ${{ matrix.host-fw }}
          mutual-auth: false
          misc: 'bpfClockProbe=false,cni.uninstall=false'

      - name: Install Cilium CLI
        if: ${{ steps.vars.outputs.downgrade_version != '' }}
        uses: cilium/cilium-cli@e7f03e4ec38a7008f4f5b9855ca9df721a9db185 # v0.18.3
        with:
          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}
          release-version: ${{ env.CILIUM_CLI_VERSION }}
          ci-version: ${{ env.cilium_cli_ci_version }}
          binary-name: cilium-cli
          binary-dir: ./

      - name: Set Kind params
        if: ${{ steps.vars.outputs.downgrade_version != '' }}
        id: kind-params
        shell: bash
        run: |
          IP_FAM="dual"
          if [ "${{ matrix.ipv6 }}" == "false" ]; then
            IP_FAM="ipv4"
          fi
          echo params="\"\" 3 \"\" \"\" ${{ matrix.kube-proxy }} $IP_FAM" >> $GITHUB_OUTPUT

      - name: Provision K8s on LVH VM
        if: ${{ steps.vars.outputs.downgrade_version != '' }}
        uses: ./.github/actions/lvh-kind
        with:
          images-folder-parent: "/tmp"
          # renovate: datasource=github-tags depName=cilium/little-vm-helper
          lvh-version: v0.0.23
          test-name: e2e-conformance
          kernel: ${{ matrix.kernel }}
          kind-params: "${{ steps.kind-params.outputs.params }}"
          kind-image: ${{ env.KIND_K8S_IMAGE }}

      - name: Start Cilium KVStore
        id: kvstore
        if: ${{ steps.vars.outputs.downgrade_version != '' && matrix.kvstore == 'true' }}
        run: |
          make kind-kvstore-start KVSTORE_POD_NAME=kvstore KVSTORE_POD_PORT=2378

          IP=$(kubectl --namespace kube-system get pod kvstore -o jsonpath='{.status.hostIP}')
          echo "config= \
            --set=etcd.enabled=true \
            --set=identityAllocationMode=kvstore \
            --set=etcd.endpoints[0]=http://${IP}:2378 \
          " >> $GITHUB_OUTPUT

      # Warning: since this is a privileged workflow, subsequent workflow job
      # steps must take care not to execute untrusted code.
      - name: Checkout pull request branch (NOT TRUSTED)
        if: ${{ steps.vars.outputs.downgrade_version != '' }}
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          ref: ${{ steps.vars.outputs.sha }}
          persist-credentials: false
          path: untrusted/cilium-newest
          sparse-checkout: |
            install/kubernetes/cilium

      - name: Checkout ${{ steps.vars.outputs.downgrade_version }} branch to get the Helm chart
        if: ${{ steps.vars.outputs.downgrade_version != '' }}
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          ref: ${{ steps.vars.outputs.downgrade_version }}
          persist-credentials: false
          path: untrusted/cilium-downgrade
          sparse-checkout: |
            install/kubernetes/cilium

      - name: Install Cilium ${{ steps.vars.outputs.downgrade_version }} (${{ matrix.name }})
        if: ${{ steps.vars.outputs.downgrade_version != '' }}
        shell: bash
        run: |
          kubectl patch node kind-worker3 --type=json -p='[{"op":"add","path":"/metadata/labels/cilium.io~1no-schedule","value":"true"}]'
          kubectl create -n kube-system secret generic cilium-ipsec-keys \
              --from-literal=keys="3+ rfc4106(gcm(aes)) $(echo $(dd if=/dev/urandom count=20 bs=1 2> /dev/null | xxd -p -c 64)) 128"

          mkdir -p cilium-junits

          CILIUM_CLI_MODE=helm ./cilium-cli install \
            ${{ steps.cilium-stable-config.outputs.config }} \
            ${{ steps.kvstore.outputs.config }}

          ./cilium-cli status --wait
          kubectl get pods --all-namespaces -o wide
          # TODO: After Cilium 1.15 release, update to cilium-dbg
          kubectl -n kube-system exec daemonset/cilium -c cilium-agent -- cilium status

      # Due to race condition after no-interrupted-connections in bpf map entries with
      # some lingering packets on the fly, we split the checks as follows:
      # 1. start 1st leak detection
      # 2.  start conn-disrupt-pods
      # 3.   cilium upgrade
      # 4.  check 1st leak detection
      # 5. check conn-disrupt
      # 6. start 2nd leak detection
      # 7.  check other conn test
      # 8. check 2nd leak detection
      - name: Prepare the bpftrace parameters
        if: ${{ steps.vars.outputs.downgrade_version != '' }}
        id: bpftrace-params
        run: |
          CILIUM_INTERNAL_IPS=$(kubectl get ciliumnode -o jsonpath='{.items[*].spec.addresses[?(@.type=="CiliumInternalIP")].ip}')
          if [[ "${{ matrix.ipv6 }}" == "false" ]]; then
            CILIUM_INTERNAL_IPS="${CILIUM_INTERNAL_IPS// / ::1 } ::1"
          fi
          echo "params=$CILIUM_INTERNAL_IPS" >> $GITHUB_OUTPUT

      - name: Start unencrypted packets check for Cilium upgrade
        if: ${{ steps.vars.outputs.downgrade_version != '' }}
        uses: ./.github/actions/bpftrace/start
        with:
          script: ./.github/actions/bpftrace/scripts/check-encryption-leaks.bt
          # As we are not testing with proxy connections during upgrades/downgrades,
          # disable the check for proxy traffic.
          args: ${{ steps.bpftrace-params.outputs.params }} "false" "ipsec"

      - name: Setup conn-disrupt-test before upgrading (${{ matrix.name }})
        if: ${{ steps.vars.outputs.downgrade_version != '' }}
        uses: ./.github/actions/conn-disrupt-test-setup

      - name: Upgrade Cilium (${{ matrix.name }})
        if: ${{ steps.vars.outputs.downgrade_version != '' }}
        shell: bash
        run: |
          CILIUM_CLI_MODE=helm ./cilium-cli upgrade --reset-values=true \
            ${{ steps.cilium-newest-config.outputs.config }} \
            ${{ steps.kvstore.outputs.config }}

          ./cilium-cli status --wait
          kubectl get pods --all-namespaces -o wide
          kubectl -n kube-system exec daemonset/cilium -c cilium-agent -- cilium-dbg status

      - name: Assert that no unencrypted packets are leaked during Cilium upgrade
        if: ${{ steps.vars.outputs.downgrade_version != '' }}
        uses: ./.github/actions/bpftrace/check

      - name: Run Conn Disrupt tests after upgrading (${{ join(matrix.*, ', ') }})
        if: ${{ steps.vars.outputs.downgrade_version != '' }}
        uses: ./.github/actions/conn-disrupt-test-check
        with:
          job-name: cilium-upgrade-${{ matrix.name }}
          full-test: 'false'

      - name: Start unencrypted packets check after Cilium upgrade
        if: ${{ steps.vars.outputs.downgrade_version != '' }}
        uses: ./.github/actions/bpftrace/start
        with:
          script: ./.github/actions/bpftrace/scripts/check-encryption-leaks.bt
          args: ${{ steps.bpftrace-params.outputs.params }} "true" "ipsec"

      - name: Run Other Conn tests after upgrading (${{ join(matrix.*, ', ') }})
        if: ${{ steps.vars.outputs.downgrade_version != '' }}
        run: |
          ./cilium-cli connectivity test --include-unsafe-tests --collect-sysdump-on-failure \
            --flush-ct \
            --sysdump-hubble-flows-count=1000000 --sysdump-hubble-flows-timeout=5m \
            --sysdump-output-filename "cilium-sysdump-other-conn-test-${{ inputs.job-name }}-<ts>" \
            --junit-file "cilium-junits/other-conn-test-${{ inputs.job-name }}.xml" \
            --junit-property github_job_step="Run other conn tests (${{ inputs.job-name }})" \
            --expected-xfrm-errors "+inbound_no_state"

      - name: Assert that no unencrypted packets are leaked after Cilium upgrade
        if: ${{ steps.vars.outputs.downgrade_version != '' }}
        uses: ./.github/actions/bpftrace/check

      - name: Start unencrypted packets check for Cilium downgrade
        if: ${{ steps.vars.outputs.downgrade_version != '' }}
        uses: ./.github/actions/bpftrace/start
        with:
          script: ./.github/actions/bpftrace/scripts/check-encryption-leaks.bt
          # As we are not testing with proxy connections during upgrades/downgrades,
          # disable the check for proxy traffic.
          args: ${{ steps.bpftrace-params.outputs.params }} "false" "ipsec"

      - name: Setup conn-disrupt-test before downgrading
        if: ${{ steps.vars.outputs.downgrade_version != '' }}
        uses: ./.github/actions/conn-disrupt-test-setup

      - name: Features tested before downgrade
        if: ${{ steps.vars.outputs.downgrade_version != '' }}
        uses: ./.github/actions/feature-status
        with:
          title: "Summary of all features tested before downgrade"
          json-filename: "${{ env.job_name }} (${{ join(matrix.*, ', ') }}) - before downgrade"
          cilium-cli: './cilium-cli'

      - name: Downgrade Cilium to ${{ steps.vars.outputs.downgrade_version }} (${{ matrix.name }})
        if: ${{ steps.vars.outputs.downgrade_version != '' }}
        shell: bash
        run: |
          CILIUM_CLI_MODE=helm ./cilium-cli upgrade --reset-values=true \
            ${{ steps.cilium-stable-config.outputs.config }} \
            ${{ steps.kvstore.outputs.config }}

          ./cilium-cli status --wait
          kubectl get pods --all-namespaces -o wide
          # TODO: After Cilium 1.15 release, update to cilium-dbg
          kubectl -n kube-system exec daemonset/cilium -c cilium-agent -- cilium status

      - name: Assert that no unencrypted packets are leaked during Cilium downgrade
        if: ${{ steps.vars.outputs.downgrade_version != '' }}
        uses: ./.github/actions/bpftrace/check

      - name: Check conn-disrupt-test after downgrading
        if: ${{ steps.vars.outputs.downgrade_version != '' }}
        uses: ./.github/actions/conn-disrupt-test-check
        with:
          job-name: cilium-downgrade-${{ matrix.name }}
          full-test: 'false'

      - name: Start unencrypted packets check after Cilium downgrade
        if: ${{ steps.vars.outputs.downgrade_version != '' }}
        uses: ./.github/actions/bpftrace/start
        with:
          script: ./.github/actions/bpftrace/scripts/check-encryption-leaks.bt
          args: ${{ steps.bpftrace-params.outputs.params }} "true" "ipsec"

      - name: Run Other Conn tests after downgrading (${{ join(matrix.*, ', ') }})
        if: ${{ steps.vars.outputs.downgrade_version != '' }}
        run: |
          ./cilium-cli connectivity test --include-unsafe-tests --collect-sysdump-on-failure \
            --flush-ct \
            --sysdump-hubble-flows-count=1000000 --sysdump-hubble-flows-timeout=5m \
            --sysdump-output-filename "cilium-sysdump-other-conn-test-${{ inputs.job-name }}-<ts>" \
            --junit-file "cilium-junits/other-conn-test-${{ inputs.job-name }}.xml" \
            --junit-property github_job_step="Run other conn tests (${{ inputs.job-name }})" \
            --expected-xfrm-errors "+inbound_no_state"

      - name: Assert that no unencrypted packets are leaked after Cilium downgrade
        if: ${{ steps.vars.outputs.downgrade_version != '' }}
        uses: ./.github/actions/bpftrace/check

      - name: Features tested after downgrade
        if: ${{ steps.vars.outputs.downgrade_version != '' }}
        uses: ./.github/actions/feature-status
        with:
          title: "Summary of all features tested after downgrade"
          json-filename: "${{ env.job_name }} (${{ join(matrix.*, ', ') }}) - after downgrade"
          cilium-cli: './cilium-cli'

      - name: Fetch artifacts
        if: ${{ steps.vars.outputs.downgrade_version != '' && !success() }}
        shell: bash
        run: |
          kubectl get pods --all-namespaces -o wide
          ./cilium-cli status
          mkdir -p cilium-sysdumps
          ./cilium-cli sysdump --output-filename cilium-sysdump-${{ matrix.name }}-final

          if [ "${{ matrix.kvstore }}" == "true" ]; then
            echo
            echo "# Retrieving Cilium etcd logs"
            kubectl -n kube-system logs kvstore
          fi

      - name: Upload artifacts
        if: ${{ steps.vars.outputs.downgrade_version != '' && !success() }}
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: cilium-sysdumps-${{ matrix.config }}-${{ matrix.mode }}
          path: cilium-sysdump-*.zip

      - name: Upload JUnits [junit]
        if: ${{ steps.vars.outputs.downgrade_version != '' && always() }}
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: cilium-junits-${{ matrix.config }}-${{ matrix.mode }}
          path: cilium-junits/*.xml

      - name: Upload features tested
        if: ${{ steps.vars.outputs.downgrade_version != '' && always() }}
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: features-tested-${{ matrix.name }}-${{ matrix.mode }}
          path: ${{ env.job_name }}*.json

      - name: Publish Test Results As GitHub Summary
        if: ${{ steps.vars.outputs.downgrade_version != '' && always() }}
        uses: aanm/junit2md@332ebf0fddd34e91b03a832cfafaa826306558f9 # v0.0.3
        with:
          junit-directory: "cilium-junits"

  merge-upload:
    if: ${{ always() }}
    name: Merge and Upload Artifacts
    runs-on: ubuntu-latest
    needs: setup-and-test
    steps:
      - name: Merge Sysdumps
        if: ${{ needs.setup-and-test.result == 'failure' }}
        uses: actions/upload-artifact/merge@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: cilium-sysdumps
          pattern: cilium-sysdumps-*
          retention-days: 5
          delete-merged: true
        continue-on-error: true
      - name: Merge JUnits
        uses: actions/upload-artifact/merge@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: cilium-junits
          pattern: cilium-junits-*
          retention-days: 5
          delete-merged: true
      - name: Merge Features tested
        uses: actions/upload-artifact/merge@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: features-tested
          pattern: features-tested-*
          retention-days: 5
          delete-merged: true

  commit-status-final:
    if: ${{ always() }}
    name: Commit Status Final
    needs: setup-and-test
    runs-on: ubuntu-latest
    steps:
      - name: Set final commit status
        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1
        with:
          sha: ${{ inputs.SHA || github.sha }}
          status: ${{ needs.setup-and-test.result }}
