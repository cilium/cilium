name: Create EKS nodegroup
description: Create EKS nodegroup
inputs:
  cluster_name:
    description: ''
    required: true
  region:
    description: ''
    required: true
  owner:
    description: ''
    required: true
  version:
    description: ''
    required: false
    default: ''
  spot:
    description: ''
    required: false
    default: 'true'
  mode:
    description: ''
    required: false
    default: ''
  client_node_number:
    description: 'Node number, will only be used for egw mode'
    required: false
    default: '4'
  egw_default_zone:
    description: 'Availability zone that will be used for egw nodegroups'
    required: false
    default: ''
  egw_no_cilium_zone:
    description: 'Availability zone that will be used for no-cilium egw nodegroup'
    required: false
    default: ''
runs:
  using: composite
  steps:
    - name: Create nodegroup details (regular mode)
      if: ${{ inputs.mode != 'egw' }}
      shell: bash
      run: |
        cat <<EOF > nodegroup-details.yaml
        managedNodeGroups:
        - name: ng-amd64
          instanceTypes:
           - t3a.medium
          desiredCapacity: 2
          spot: ${{ inputs.spot }}
          privateNetworking: true
          volumeType: "gp3"
          volumeSize: 25
          taints:
           - key: "node.cilium.io/agent-not-ready"
             value: "true"
             effect: "NoExecute"
        - name: ng-arm64
          instanceTypes:
           - t4g.medium
          desiredCapacity: 1
          spot: ${{ inputs.spot }}
          privateNetworking: true
          volumeType: "gp3"
          volumeSize: 25
          taints:
           - key: "node.cilium.io/agent-not-ready"
             value: "true"
             effect: "NoExecute"
        EOF

    - name: Create nodegroup details (EGW mode)
      if: ${{ inputs.mode == 'egw' }}
      shell: bash
      run: |
        cat <<EOF > nodegroup-details.yaml
        managedNodeGroups:
        - name: ng-amd64-client
          instanceTypes:
           - m5n.xlarge
          availabilityZones:
           - ${{ inputs.egw_default_zone }}
          desiredCapacity: ${{ inputs.client_node_number }}
          spot: false
          privateNetworking: true
          volumeType: "gp3"
          volumeSize: 20
          maxPodsPerNode: 110
          taints:
           - key: "node.cilium.io/agent-not-ready"
             value: "true"
             effect: "NoExecute"
          labels:
             role.scaffolding/egw-client: "true"
        - name: ng-amd64-egw-node
          instanceTypes:
           - m5n.xlarge
          availabilityZones:
           - ${{ inputs.egw_default_zone }}
          desiredCapacity: 1
          spot: false
          privateNetworking: true
          volumeType: "gp3"
          volumeSize: 20
          maxPodsPerNode: 110
          taints:
           - key: "node.cilium.io/agent-not-ready"
             value: "true"
             effect: "NoExecute"
          labels:
             role.scaffolding/egw-node: "true"
        - name: ng-amd64-heapster
          instanceTypes:
           - m5n.xlarge
          availabilityZones:
           - ${{ inputs.egw_default_zone }}
          desiredCapacity: 1
          spot: false
          privateNetworking: true
          volumeType: "gp3"
          volumeSize: 20
          maxPodsPerNode: 110
          taints:
           - key: "node.cilium.io/agent-not-ready"
             value: "true"
             effect: "NoExecute"
          labels:
             role.scaffolding/monitoring: "true"
        - name: ng-amd64-no-cilium
          instanceTypes:
           - m5n.xlarge
          availabilityZones:
           - ${{ inputs.egw_no_cilium_zone }}
          desiredCapacity: 1
          spot: false
          privateNetworking: true
          volumeType: "gp3"
          volumeSize: 20
          taints:
           - key: "cilium.io/no-schedule"
             value: "true"
             effect: "NoSchedule"
          labels:
            cilium.io/no-schedule: "true"
          # Manually inject a dummy CNI configuration to let the Kubelet turn
          # ready. This is necessary as otherwise the node creation would
          # never complete. Regardless, no pods will be scheduled here given
          # that the node is tainted.
          preBootstrapCommands:
          - "echo '{ \"cniVersion\": \"0.3.1\", \"name\": \"dummy\", \"type\": \"dummy-cni\", \"log-file\": \"/var/run/dummy.log\" }' > /etc/cni/net.d/05-dummy.conf"
        EOF

    - name: Create EKS nodegroup
      shell: bash
      run: |
        cat <<EOF > eks-nodegroups.yaml
        apiVersion: eksctl.io/v1alpha5
        kind: ClusterConfig

        metadata:
          name: ${{ inputs.cluster_name }}
          region: ${{ inputs.region }}
          version: "${{ inputs.version }}"
          tags:
           usage: "${{ github.repository_owner }}-${{ github.event.repository.name }}"
           owner: "${{ inputs.owner }}"

        EOF

        cat ./nodegroup-details.yaml >> ./eks-nodegroups.yaml

        eksctl create nodegroup -f ./eks-nodegroups.yaml
