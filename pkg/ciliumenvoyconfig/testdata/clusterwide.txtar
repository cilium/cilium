# Test handling of CiliumClusterwideEnvoyConfig

# Start the hive and wait for tables to be synchronized before adding k8s objects.
hive start
db/initialized

# Start with clean state.
db/cmp services services_empty.table
db/cmp ciliumenvoyconfigs cec_empty.table

# Set up the services and endpoints
k8s add service.yaml endpointslice.yaml
db/cmp services services.table

# Add the CiliumClusterwideEnvoyConfig and wait for it to be ingested.
k8s add ccec.yaml
db/cmp ciliumenvoyconfigs cec.table

# Check that both services are now redirected to proxy.
db/cmp services services_redirected.table

# Check that right updates towards Envoy happened.
envoy envoy.out
* cmp envoy.out envoy1.expected

# Test the processing other way around, e.g. CEC exists before
# the service.
k8s delete service.yaml endpointslice.yaml
db/cmp services services_empty.table

# Backends towards Envoy should be updated.
envoy envoy.out
* cmp envoy.out envoy2.expected

# Add back the service and endpoints
k8s add service.yaml endpointslice.yaml
db/cmp services services_redirected.table

# Check again that updates happened.
envoy envoy.out
* cmp envoy.out envoy3.expected

# Cleanup. Remove CEC and check that proxy redirect is gone.
k8s delete ccec.yaml
db/cmp services services.table
db/cmp ciliumenvoyconfigs cec_empty.table

# The listener should now be deleted.
envoy envoy.out
* cmp envoy.out envoy4.expected

# ---------------------------------------------

-- services_empty.table --
Name        ProxyRedirect

-- services.table --
Name        ProxyRedirect
test/echo2    

-- services_redirected.table --
Name        ProxyRedirect
test/echo2  1000

-- cec_empty.table --
Name    Services

-- cec.table --
Name                  Selected  Services    Listeners
/envoy-lb-listener-2  true      test/echo2  /envoy-lb-listener-2/envoy-lb-listener-2:1000

-- ccec.yaml --
apiVersion: cilium.io/v2
kind: CiliumClusterwideEnvoyConfig
metadata:
  name: envoy-lb-listener-2
spec:
  services:
    - name: echo2
      namespace: test
  resources:
    - "@type": type.googleapis.com/envoy.config.listener.v3.Listener
      name: envoy-lb-listener-2

-- service.yaml --
apiVersion: v1
kind: Service
metadata:
  name: echo2
  namespace: test
  uid: a49fe99c-3564-4754-acc4-780f2331a49b
spec:
  clusterIP: 10.96.50.104
  clusterIPs:
  - 10.96.50.104
  ports:
  - name: http
    nodePort: 30781
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    name: echo2
  type: NodePort
status:
  loadBalancer: {}

-- endpointslice.yaml --
apiVersion: discovery.k8s.io/v1
kind: EndpointSlice
metadata:
  labels:
    kubernetes.io/service-name: echo2
  name: echo2-eps1
  namespace: test
  uid: d1f517f6-ab88-4c76-9bd0-4906a17cdd76
addressType: IPv4
endpoints:
- addresses:
  - 10.244.1.2
  conditions:
    ready: true
    serving: true
    terminating: false
  nodeName: nodeport-worker
ports:
- name: tcp
  port: 8081
  protocol: TCP

-- envoy1.expected --
policy-trigger-count: 1
update: count=1 listeners=/envoy-lb-listener-2/envoy-lb-listener-2/1000 endpoints=test/echo2:*=,test/echo2=
delete: count=0 listeners=<nil> endpoints=<nil>
-- envoy2.expected --
policy-trigger-count: 1
update: count=1 listeners=/envoy-lb-listener-2/envoy-lb-listener-2/1000 endpoints=test/echo2:*=,test/echo2=
delete: count=0 listeners=<nil> endpoints=<nil>
-- envoy3.expected --
policy-trigger-count: 1
update: count=1 listeners=/envoy-lb-listener-2/envoy-lb-listener-2/1000 endpoints=test/echo2:*=,test/echo2=
delete: count=0 listeners=<nil> endpoints=<nil>
-- envoy4.expected --
policy-trigger-count: 2
update: count=1 listeners=/envoy-lb-listener-2/envoy-lb-listener-2/1000 endpoints=test/echo2:*=,test/echo2=
delete: count=1 listeners=/envoy-lb-listener-2/envoy-lb-listener-2/1000 endpoints=test/echo2:*=,test/echo2=
