name: Multicluster

# Any change in triggers needs to be reflected in the concurrency group.
on:
  pull_request_target: {}
  # Run every 6 hours
  schedule:
    - cron:  '0 3/6 * * *'

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || 'scheduled' }}
  cancel-in-progress: true

env:
  clusterName1: ${{ github.repository_owner }}-${{ github.event.repository.name }}-${{ github.run_id }}-mesh-1
  clusterName2: ${{ github.repository_owner }}-${{ github.event.repository.name }}-${{ github.run_id }}-mesh-2
  zone: us-west2-a
  firewallRuleName: ${{ github.repository_owner }}-${{ github.event.repository.name }}-${{ github.run_id }}-rule

jobs:
  installation-and-connectivity:
    if: ${{ github.repository == 'cilium/cilium-cli' }}
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - name: Checkout
        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f

      - name: Set up gcloud CLI
        uses: google-github-actions/setup-gcloud@daadedc81d5f9d3c06d2c92f49202a3cc2b919ba
        with:
          project_id: ${{ secrets.GCP_PR_PROJECT_ID }}
          service_account_key: ${{ secrets.GCP_PR_SA_KEY }}
          export_default_credentials: true

      - name: Display gcloud CLI info
        run: |
          gcloud info

      - name: Set up job variables
        id: vars
        run: |
          if [ ${{ github.event.issue.pull_request || github.event.pull_request }} ]; then
            PR_API_JSON=$(curl \
              -H "Accept: application/vnd.github.v3+json" \
              -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
              ${{ github.event.issue.pull_request.url || github.event.pull_request.url }})
            SHA=$(echo "$PR_API_JSON" | jq -r ".head.sha")
            OWNER=$(echo "$PR_API_JSON" | jq -r ".number")
          else
            SHA=${{ github.sha }}
            OWNER=${{ github.sha }}
          fi

          echo ::set-output name=sha::${SHA}
          echo ::set-output name=owner::${OWNER}

      - name: Create GKE cluster 2
        run: |
          gcloud container clusters create ${{ env.clusterName2 }} \
            --labels "usage=${{ github.repository_owner }}-${{ github.event.repository.name }},owner=${{ steps.vars.outputs.owner }}" \
            --zone ${{ env.zone }} \
            --image-type COS_CONTAINERD \
            --num-nodes 2 \
            --machine-type e2-custom-2-4096 \
            --disk-type pd-standard \
            --disk-size 10GB \
            --node-taints node.cilium.io/agent-not-ready=true:NoSchedule \
            --preemptible \
            --enable-ip-alias

      - name: Get cluster 2 credentials
        run: |
          gcloud container clusters get-credentials ${{ env.clusterName2 }} --zone ${{ env.zone }}

      - name: Create gcloud-free kubeconfig for cluster 2
        run: |
          .github/get-kubeconfig.sh
          mv kubeconfig kubeconfig-cluster2

      - name: Create GKE cluster 1
        run: |
          gcloud container clusters create ${{ env.clusterName1 }} \
            --labels "usage=${{ github.repository_owner }}-${{ github.event.repository.name }},owner=${{ steps.vars.outputs.owner }}" \
            --zone ${{ env.zone }} \
            --image-type COS_CONTAINERD \
            --num-nodes 2 \
            --machine-type e2-custom-2-4096 \
            --disk-type pd-standard \
            --disk-size 10GB \
            --node-taints node.cilium.io/agent-not-ready=true:NoSchedule \
            --preemptible \
            --enable-ip-alias

      - name: Get cluster 1 credentials
        run: |
          gcloud container clusters get-credentials ${{ env.clusterName1 }} --zone ${{ env.zone }}

      - name: Allow cross-cluster traffic
        run: |
          TAG1=$(gcloud compute firewall-rules list --filter="name~^gke-${{ env.clusterName1 }}-[0-9a-z]*-all$" --format="value(name)")
          TAG2=$(gcloud compute firewall-rules list --filter="name~^gke-${{ env.clusterName2 }}-[0-9a-z]*-all$" --format="value(name)")
          gcloud compute firewall-rules describe $TAG1
          gcloud compute firewall-rules describe $TAG2
          gcloud compute firewall-rules create ${{ env.firewallRuleName }} --allow tcp,udp,icmp,sctp,esp,ah --priority=999 --source-ranges=10.0.0.0/9 --target-tags=${TAG1/-all/-node},${TAG2/-all/-node}
          gcloud compute firewall-rules describe ${{ env.firewallRuleName }}

      - name: Create gcloud-free kubeconfig for cluster 1, merge kubeconfigs and put them in configmap
        run: |
          .github/get-kubeconfig.sh
          mv kubeconfig kubeconfig-cluster1
          go run .github/tools/kubeconfig-merger/main.go kubeconfig-cluster1 kubeconfig-cluster2 kubeconfig
          kubectl create configmap cilium-cli-kubeconfig -n kube-system --from-file kubeconfig

      - name: Load cilium test script in configmap
        run: |
          kubectl create configmap cilium-cli-test-script -n kube-system --from-file=in-cluster-test-script.sh=.github/in-cluster-test-scripts/multicluster.sh

      - name: Create cilium-cli test job
        run: |
          helm install .github/cilium-cli-test-job-chart \
            --generate-name \
            --set tag=${{ steps.vars.outputs.sha }} \
            --set job_name=cilium-cli \
            --set test_script_cm=cilium-cli-test-script \
            --set cluster_name_1=${{ env.clusterName1 }} \
            --set cluster_name_2=${{ env.clusterName2 }} \

      - name: Wait for test job
        run: |
          kubectl -n kube-system wait job/cilium-cli --for=condition=complete --timeout=20m

      - name: Post-test information gathering
        if: ${{ !success() }}
        run: |
          echo "=== Retrieve in-cluster jobs logs ==="
          kubectl logs --timestamps -n kube-system job/cilium-cli

          echo "\n\n\n=== Install latest stable CLI ==="
          curl -LO https://github.com/cilium/cilium-cli/releases/latest/download/cilium-linux-amd64.tar.gz
          sudo tar xzvfC cilium-linux-amd64.tar.gz /usr/bin
          rm cilium-linux-amd64.tar.gz

          echo "\n\n\n=== Retrieve cluster1 state ==="
          export KUBECONFIG=kubeconfig-cluster1
          kubectl get pods --all-namespaces -o wide
          cilium status
          cilium clustermesh status
          cilium sysdump --output-filename cilium-sysdump-cluster1

          echo "\n\n\n=== Retrieve cluster2 state ==="
          export KUBECONFIG=kubeconfig-cluster2
          kubectl get pods --all-namespaces -o wide
          cilium status
          cilium clustermesh status
          cilium sysdump --output-filename cilium-sysdump-cluster2
        shell: bash {0} # Disable default fail-fast behaviour so that all commands run independently

      - name: Clean up GKE
        if: ${{ always() }}
        run: |
          gcloud compute firewall-rules delete ${{ env.firewallRuleName }} --quiet
          gcloud container clusters delete ${{ env.clusterName1 }} --zone ${{ env.zone }} --quiet --async
          gcloud container clusters delete ${{ env.clusterName2 }} --zone ${{ env.zone }} --quiet --async
        shell: bash {0} # Disable default fail-fast behaviour so that all commands run independently

      - name: Upload artifacts
        if: ${{ !success() }}
        uses: actions/upload-artifact@ee69f02b3dfdecd58bb31b4d133da38ba6fe3700
        with:
          name: cilium-sysdump-out.zip
          path: |
            cilium-sysdump-cluster1.zip
            cilium-sysdump-cluster2.zip
          retention-days: 5

      - name: Send slack notification
        if: ${{ !success() && (github.event_name == 'schedule' || github.event_name == 'push') }}
        uses: 8398a7/action-slack@dcc8c8e9dd8802e21a712dc0c003db97b42efe43
        with:
          status: ${{ job.status }}
          fields: repo,message,commit,author,action,eventName,ref,workflow,job,took
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
